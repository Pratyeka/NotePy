### 线程同步
- 线程同步：线程间协同，通过某种技术，让一个线程访问修改某些数据时，其余线程不能同时对该数据进行修改操作
- 不同操作系统的实现技术有所不同：临界区(citical section)、互斥量(mutex)、信号量（semaphore）、事件Event

#### Event类
- 线程间通信最简单的机制，*使用一个内部标记*来控制是否可以对数据进行操作
    - 初始化实例时的内部标记值为`False`
- 实例方法：
    - `set()`:    标记设置为`True`
    - `clear()`:  标记设置为`False` 
    - `is_set()`: 标记是否为`True` (用在判定语句中)
    - `wait(timeout=None)`: 设置等待标记为True的时长，None为无限等待(阻塞)
        - 等到标记变化为True，返回True
        - 未等到且超时，返回False
        - *在实际使用中不限制等待线程的个数* 
- *Event的wait优于time.sleep,会更快的切换到其他线程，提高并发效率*

```Python
    from threading import Event,Thread
    import time
    import logging

    FORMAT = '%(asctime)s %(threadName)s %(message)s'
    logging.basicConfig(format=FORMAT, level=logging.INFO)

    # event对象作为参数来控制两个线程间的同步状态
    def boss(event:Event):
        logging.info("I'm boss, waiting for U.")
        event.wait()   # 返回bool值，等待flag变为True，返回True。超时变为False
        logging.info("Good Job.")

    def worker(event:Event, count=10):
        logging.info("I'm working for U.")
        cups = []
        while True:
            logging.info('make 1')
            time.sleep(0.5)
            cups.append(1)
            if len(cups) >= count:
                event.set()
                break
        logging.info('I finished my job. cups={}'.format(cups))

    event = Event()
    w = Thread(target=worker, args=(event,10))
    b = Thread(target=boss, args=(event,))
    w.start()
    b.start()
```

#### Lock类
- 在有共享资源争抢的地方都可以使用锁，从而保证只有一个使用者可以完全使用该资源
- 一旦线程获得锁，其他试图获取锁的线程将被阻塞
- 实例方法：
    - `acquire(blocking=True, timeout=-1):`默认阻塞，阻塞可以设置超时时间
        - 成功获取锁，返回True，否则返回False
    - `realse():` 释放锁，可以从任何线程中调用释放
        - 已上锁的锁，会被重置为unlock状态
        - 没上锁的锁，抛出RuntimeError异常
- 在解锁前代码出现异常，锁就无法释放，但是当前线程结束，产生死锁
- 防止死锁的语句：
    - 使用`try...finally`语句可以保证锁的释放
    - **with上下文管理语句，锁对象支持上下文管理**
- 锁的使用场景
    - 适用于访问和修改同一个资源的时候，全部是读取同一个资源不需要使用锁
- 使用锁的注意事项：
    - 少用锁，必要时使用锁，锁会带来效率问题，并行变串行（排队或者争抢）
    - 加锁时间越短越好，不需要就立即释放锁
    - 一定要避免死锁
```Python
    from threading import Event,Thread, Lock
    import logging
    import threading

    FORMAT = '%(asctime)s %(threadName)s %(message)s'
    logging.basicConfig(format=FORMAT, level=logging.INFO)

    event = Event()

    class Counter:
        def __init__(self):
            self._val = 0
            self._lock = Lock()

        @property
        def value(self):
            with self._lock:
                return self._val

        def inc(self):
            with self._lock:    # 上下文管理防止出现争抢导致结果不一致
                self._val += 1

        def dec(self):
            with self._lock:
                self._val -= 1

    def run(c:Counter, count=100):
        for _ in range(count):
            for i in range(-50, 50):
                if i < 0:
                    c.dec()
                else:
                    c.inc()

    counter = Counter()
    for i in range(10000):
        Thread(target=run, args=(counter,10)).start()

    while True:
        if threading.active_count() == 1:
            print('the cal num is {}'.format(counter.value))
            break
```

#### 可重入锁RLock
- 可重入锁是线程相关的锁，线程A可以重复获取锁，并多次成功，不会阻塞
    - 要求在线程中做和acquire次数相同的relase操作
- 与线程相关，在本线程中多次获取不会阻塞。当锁未释放完，其他线程获取锁就会阻塞

#### Condition类（通知机制，避免消费者反复查询）
- 构造函数：`Condition(lock=None)`,可以传入Lock对象或者RLock对象，默认RLock
- 实例方法：
    - `acquire(*args)`: 获取锁
    - `wait(self, timeout=None)`: 等待或超时
    - `notify(n=1)`： 唤醒至多指定数目个数的等待的线程，没有等待的线程就没有操作
    - `notify_all()`: 唤醒所有等待线程
- 一般用来生产者、消费者模型，为了解决生产者消费者速度匹配问题
    - 如果消费者反复查询，是否有可使用数据，会造成性能问题
- *建议使用上下文管理的方式来操作锁的开关*
- 因为采用了通知机制，非常有效率


```Python
    from threading import Thread, Event, Condition
    import random
    import logging

    FORMAT = '%(asctime)s %(threadName)s %(message)s'
    logging.basicConfig(format=FORMAT, level=logging.INFO)

    class Dispatcher:
        def __init__(self):
            self.data = None
            self.event = Event()
            self.cond = Condition()

        def produce(self, total):
            for _ in range(total):
                data = random.randint(0,100)
                with self.cond:
                    logging.info(data)
                    self.data = data
                    self.cond.notify_all()
                self.event.wait(0.3)   # 模拟生产速度
            self.event.set()           # 不生产时的通知

        def cousume(self):
            while not self.event.is_set():   # 生产者在生产时才进来
                with self.cond:
                    self.cond.wait(timeout=3) # 防止最后生产者不生产数据时无法获取消息
                    logging.info("received {}".format(self.data))
                    self.data = None
                self.event.wait(0.2)   # 模拟消费速度

    d = Dispatcher()
    p = Thread(target=d.produce, args=(10,), name='produce')
    c = Thread(target=d.cousume, name='consumer')
    # 先启动消费者，再启动生产者
    c.start()
    p.start()
```


#### Barrier
- 所有线程冲到了Barrier前等待，直到到达parties数目，屏障打开，所有线程不再等待，继续执行
- 构建对象：`Barrier(parties, action=None, timeout=None)`
    - `parties`：指定参与方数目
    - `timeout`：wait方法未指定超时时间时的默认值
- `n_waiting`: 当前屏障中等待的线程数
- `wait(timeout=None)`: 等待通过屏障，返回0-(线程数-1)的整数，每个线程返回不同
    - 如果设置超时时间，超时时屏障处于broken状态
- `broken`: 如果屏障处于打破状态，返回True
- `abort()`: 将屏障置于broken状态，reset方法可以恢复broken状态
    - 等待中的线程抛出BrokenBarrierError
    - 调用等待方法的线程也会抛出BrokenBarrierError
- `reset()`: 恢复屏障，重新开始拦截

```Python
    import threading
    import logging

    FORMAT = '%(asctime)s %(threadName)s %(thread)d %(message)s'
    logging.basicConfig(format=FORMAT, level=logging.INFO)

    def worker(barrier):
        logging.info('barrier-{}'.format(barrier.n_waiting))
        try:
            # 所有线程冲到了Barrier前等待，到达了parties的数目
            # 屏障打开，所有线程停止等待，继续运行
            barrier_id = barrier.wait()
            logging.info('barrier {} runing'.format(barrier_id))
        except threading.BrokenBarrierError:
            logging.info('Broken status')

    barr = threading.Barrier(3)

    for thread in range(6):
        # 设置broken状态
        # waiting的线程抛出BrokenBarrierError异常
        # 新waiting的线程也抛出异常
        if thread == 2:
            barr.abort()
        # 恢复屏障，继续按照parties数目要求继续拦截线程
        elif thread == 4:
            barr.reset()
        threading.Thread(target=worker, args=(barr,)).start()
```
- Barrier应用
    - 并发初始化：所有线程的工作完成后，才可以继续工作

### semaphore信号量
- 类似于Lock机制，信号量对象内部维护了一个倒计数器
    - 执行acquire都会减1,执行release就会加1
    - 在计数器的值为0时，调用acquire会发生阻塞，直到有release发生才会继续执行
- `Semaphore(value=1)`: 构造方法。value小于0，抛ValueError异常
- `acquire(blocking=True, timeout=None)`: 获取信号量，计数器减1，获取成功返回True
- `release()`: 释放信号量，计数器加1
- *注：在没有使用信号量之前，就使用release，会导致计数器超出上线*
```Python
    from threading import Event,Semaphore,Thread
    import logging

    FORMAT = '%(asctime)s %(threadName)s %(message)s'
    logging.basicConfig(format=FORMAT, level=logging.INFO)

    def worker(s:Semaphore):
        logging.info('in sub thread')
        logging.info(s.acquire())
        logging.info('sub thread over')

    # 三次acquire将获取全部的锁
    s = Semaphore(3)
    # 返回True
    logging.info(s.acquire())
    print(s._value)
    logging.info(s.acquire())
    print(s._value)
    logging.info(s.acquire())
    print(s._value)

    # 线程获取锁，导致线程阻塞
    Thread(target=worker, args=(s,)).start()
    Event().wait(2)

    # 非阻塞获取锁，返回False
    logging.info(s.acquire(False))
    # 设置少时时间的获取锁
    logging.info(s.acquire(timeout=3))

    logging.info('release')
    # 释放锁，工作线程继续执行
    s.release()
```
- 连接池（减少反复开启线程带来的资源消耗）
```Python
    import threading
    import logging

    FORMAT = '%(asctime)s %(threadName)s %(message)s'
    logging.basicConfig(format=FORMAT, level=logging.INFO)

    class Conn:
        def __init__(self, name):
            self.name = name

        def __repr__(self):
            return 'conn {}'.format(self.name)

    class Pool:
        def __init__(self, conn_num):
            self.sema = threading.Semaphore(conn_num)
            self.pool = [self._conn('conn-{}'.format(i)) for i in range(conn_num)]

        @staticmethod
        def _conn(name):
            return Conn(name)

        def get(self):
            self.sema.acquire()
            return self.pool.pop()

        def set(self, conn):
            self.pool.append(conn)
            self.sema.release()

    pool = Pool(3)

    def worker(pool:Pool):
        conn = pool.get()
        logging.info(conn)

        threading.Event().wait(3)
        pool.set(conn)

    for i in range(6):
        threading.Thread(target=worker, args=(pool,)).start()
```

### BoundedSemaphore类
- 有界的信号量，不允许使用release超出初始值的范围，否则，抛出ValueError异常
- 没有获得信号量的线程都被阻塞，也就是只有顺利获得锁的才可以release，安全

### 信号量和锁
- 锁，只允许同一时间一个线程独占资源。是信号量计数器初始值为1的信号量
- 信号量，可以多个线程访问共享资源，但是这个共享资源数量有限

### Queue的容器大小不准确原因
- Queue类是线程安全的，适用于多线程间安全的交换数据。内部使用了Lock和Condition
- *为什么实现容器的大小是不准确的：*
    - 在Queue中，获取队列大小的函数是线程安全的，读取数据的函数也是线程安全的
    - 但是这两句组成的语句块没有原子性，会被中断。因此数据大小是不准确的
```Python
    import queue

    q = queue.Queue(8)

    # 下面两句没有原子性，所以会造成容器大小不安全
    if q.qsize() == 7: 
        q.put()

    if q.qsize() == 1:
        q.get()
```

### GIL（全局解释器锁）
- 在CPython解释器进程级别有一把锁，叫做GIL全局解释器锁
- GIL保证在CPython进程中，只有一个线程执行字节码，甚至在多CPU时，也是如此

- CPython中
    - IO密集性：由于线程阻塞，会调度其他线程（多线程）
    - CPU密集型：当前线程会连续获得GIL，导致其他线程几乎无法使用CPU（多进程）

- Python中绝大多数内置数据结构的读写都是原子操作
- 由于GIL的存在，Python的内置数据类型在多线程编程时就编程安全的了，但其实不是线程安全类型

- 针对计算密集型：在CPython中多线程根本没有任何优势，和一个线程执行时间相当
```Python
    from threading import Thread
    import logging
    import datetime

    FORMAT = '%(asctime)s %(threadName)s %(message)s'
    logging.basicConfig(format=FORMAT, level=logging.INFO)

    def calc():
        sum = 0
        for _ in range(10000000):
            sum += 1

    start = datetime.datetime.now()
    calc()
    calc()
    calc()
    calc()
    calc()

    delta = (datetime.datetime.now() - start).total_seconds()
    logging.info(delta)

    #GIL锁导致多线程类似于单线程的执行方式
    start = datetime.datetime.now()
    t1 = Thread(target=calc)
    t2 = Thread(target=calc)
    t3 = Thread(target=calc)
    t4 = Thread(target=calc)
    t5 = Thread(target=calc)
    t1.start()
    t2.start()
    t3.start()
    t4.start()
    t5.start()
    t1.join()
    t2.join()
    t3.join()
    t4.join()
    t5.join()
    delta = (datetime.datetime.now() - start).total_seconds()
    logging.info(delta)
```